# LLM API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Server Configuration
PORT=3000
NODE_ENV=development

# Output Configuration
SAVE_TO_FILE=true
OUTPUT_FILE_PATH=./output/conversation.json
DISPLAY_IN_CONSOLE=true

# Error Handling
ERROR_STRATEGY=retry
MAX_RETRIES=3
INITIAL_DELAY=1000